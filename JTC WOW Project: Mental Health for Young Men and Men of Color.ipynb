{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mental Health for Young Men and Men of Color**#\n",
    "\n",
    "**By : Jeneil Stallion and Hernan Carvente-Martinez**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As behavioral health advocates who work in the public health field, our passion is to raise awareness on behavioral health in our community. Historically and currently, men of color—-particularly African-American and Latinx, are overburdened by unaddressed mental and behavioral health disparities; often this stems from adverse childhood experiences and/or structural violence leading into adulthood. Within the field of behavioral health, Black and Brown men are under-represented in this profession. It can be an asset to have health professionals within the care network who have cultural context and lived experience addressing trauma as men of color, so we decided to show the disparity of resources targeted towards young men and men of color.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our project highlights the disparities of mental health resources specifically for young men and men of color. We chose to do research on NAMI (National Alliance on Mental Illness), and NIMH (National Institute of Mental Health), two of the top mental health organizations in the country. To accomplish this task, we used the following skills and resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python’s requests library\n",
    "- Beautiful soup to parse and web scrape the data\n",
    "- Created a For loop to iterate through specific ‘Keywords” and return search results\n",
    "- Defined functions to pull specific information from html documents and return data\n",
    "- Created a CSV file of parsed information from NAMI and NIMH websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NIMH (National Institute of Mental Health) Web Scrape by : Jeneil Stallion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import BeautifulSoup, Pythons's requests library, and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define webpage url to get data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nimh.nih.gov/health/find-help/index.shtml#part_150431'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request a response to make sure the website is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out contents of website to view html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create soup object to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the domain's url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nimh_domain = 'https://www.nimh.gov'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function get_link_info(title) which pulls the title and information of the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #define a function to get url info. Takes one argument (title)\n",
    "    def get_link_info(title):\n",
    "    #create a list to append data into\n",
    "\tdata = []\n",
    "    #create for loop that iterates through html element'section' and title: data-cms-title'\n",
    "    #FindAll ('a') tags in specified section\n",
    "    #'a' is an acnchor element that creates a hyperlink to webpages. url\n",
    "    #The url link in the soup.find 'section', {\"data-cms-title\": title}).findAll('a') = url\n",
    "\tfor link in soup.find('section', {\"data-cms-title\": title}).findAll('a'):\n",
    "\t\turl = ''\n",
    "\t\tif 'http://' in link['href']:\n",
    "        #if there is 'http://' in the links url, set the url to the specific link hyperlink\n",
    "\t\t\turl = link['href']\n",
    "            #else if https:// is in the link['href'], set the url to the specific link hyperlink\n",
    "\t\telif 'https://' in link['href']:\n",
    "\t\t\turl = link['href']\n",
    "            #or else add the nimh_domain url name before the 'href' link\n",
    "\t\telse: \n",
    "\t\t\turl = f\"{nimh_domain}{link['href']}\"\n",
    "        #print out the text contents of the url link\n",
    "\t\tprint(link.text)\n",
    "        #I created these set of if statements because some links had inproper https:// adresses\n",
    "        #Set parent folder to a variable with with the 'p' element to access content and child folders\n",
    "\t\tparent = link.find_parent('p')\n",
    "        #Print text of parent folder with the 'p' element\n",
    "\t\tprint(parent.text)\n",
    "        #Iterate through parent folders to find contents of children folders\n",
    "\t\tfor child in soup.p.children:\n",
    "        #print text in children folders in the parent folder\n",
    "\t\t\tprint(child)\n",
    "            #Iterate through all '<br>' tags to remove them from code output. \n",
    "\t\t\tfor e in soup.findAll('br'):\n",
    "                #.extract removes all of the line break elements (<br>) \n",
    "\t\t\t\te.extract()\n",
    "        #Create variable for the 'Link' key value 'url' & 'Description' key value 'link.text'\n",
    "\t\tlink_info = {'Link': url , 'Desription':link.text}\n",
    "        #append parsed data info into the data list\n",
    "\t\tdata.append(link_info)\n",
    "    #end the function return data result\n",
    "\treturn data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get healthcare resources info. Takes one argument(title)\n",
    "def get_healthcare_info(title):\n",
    "    #create empty list to append data into\n",
    "\thealthcare_data = []\n",
    "    #create for loop that iterates through html element'section' and title: data-cms-title'\n",
    "    #Similar to the get_link_info() function. I created two different functions beacuse the data was in different sections of webpage with different elements.\n",
    "\tfor link in soup.find('section', {\"data-cms-title\": title}).findAll('a'):\n",
    "\t\turl = ''\n",
    "        #if there is 'http://' in the links url, set the url to the specific link hyperlink\n",
    "\t\tif 'http://' in link['href']:\n",
    "\t\t\turl = link['href']\n",
    "             #else if https:// is in the link['href'], set the url to the specific link hyperlink\n",
    "\t\telif 'https://' in link['href']:\n",
    "\t\t\turl = link['href']\n",
    "             #or else add the nimh_domain url name before the 'href' link\n",
    "\t\telse: \n",
    "\t\t\turl = f\"{nimh_domain}{link['href']}\"\n",
    "            # #or else add the nimh_domain name to the link\n",
    "\t\tprint(link.text)\n",
    "        #print conents of link\n",
    "\t\tlink_info = {'Link': url , 'Desription':link.text}\n",
    "        #Define link info with parsed data\n",
    "\t\thealthcare_data.append(link_info)\n",
    "        #append data to healthcare_info list\n",
    "\treturn healthcare_data\n",
    "        #return data to healtcare_data list and end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Suicide Prevention Lifeline\n",
      "National Suicide Prevention LifelineCall 1-800-273-TALK (8255); En Español 1-888-628-9454 The Lifeline is a free, confidential crisis hotline that is available to everyone 24 hours a day, seven days a week. The Lifeline connects callers to the nearest crisis center in the Lifeline national network. These centers provide crisis counseling and mental health referrals. People who are deaf, hard of hearing, or have hearing loss can contact the Lifeline via TTY at 1-800-799-4889.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Crisis Text Line\n",
      "Crisis Text LineText “HELLO” to 741741 The Crisis Text hotline is available 24 hours a day, seven days a week throughout the U.S. The Crisis Text Line serves anyone, in any type of crisis, connecting them with a crisis counselor who can provide support and information.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Veterans Crisis Line\n",
      "Veterans Crisis Line Call 1-800-273-TALK (8255) and press 1 or text to 838255 The Veterans Crisis Line is a free, confidential resource that connects veterans 24 hours a day, seven days a week with a trained responder. The service is available to all veterans, even if they are not registered with the VA or enrolled in VA healthcare. People who are deaf, hard of hearing, or have hearing loss can call 1-800-799-4889.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Disaster Distress Helpline\n",
      "Disaster Distress HelplineCall 1-800-985-5990 or text “TalkWithUs” to 66746 The disaster distress helpline provides immediate crisis counseling for people who are experiencing emotional distress related to any natural or human-caused disaster. The helpline is free, multilingual, confidential, and available 24 hours a day, seven days a week.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Contact social media outlets directly\n",
      "Contact social media outlets directly if you are concerned about a friend’s social media updates or dial 911 in an emergency.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "NIMH 5 action steps for helping someone in emotional pain\n",
      "View the NIMH 5 action steps for helping someone in emotional pain infographic to see how you can help those in distress.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "National Suicide Prevention Lifeline\n",
      "Crisis Text Line\n",
      "Veterans Crisis Line\n",
      "Disaster Distress Helpline\n",
      "Contact social media outlets directly\n",
      "NIMH 5 action steps for helping someone in emotional pain\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Link': 'http://suicidepreventionlifeline.org/',\n",
       "  'Desription': 'National Suicide Prevention Lifeline'},\n",
       " {'Link': 'http://www.crisistextline.org/', 'Desription': 'Crisis Text Line'},\n",
       " {'Link': 'https://www.veteranscrisisline.net/',\n",
       "  'Desription': 'Veterans Crisis Line'},\n",
       " {'Link': 'https://www.samhsa.gov/find-help/disaster-distress-helpline',\n",
       "  'Desription': 'Disaster Distress Helpline'},\n",
       " {'Link': 'https://suicidepreventionlifeline.org/help-someone-else/safety-and-support-on-social-media/',\n",
       "  'Desription': 'Contact social media outlets directly'},\n",
       " {'Link': 'https://www.nimh.gov/health/publications/5-action-steps-for-helping-someone-in-emotional-pain/index.shtml',\n",
       "  'Desription': 'NIMH 5 action steps for helping someone in emotional pain'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_link_info('Get Immediate Help in a Crisis')\n",
    "#Now the functions are ready to use and takes one arguement (title)\n",
    "#use get_link_info() funtion to get contents of specified section title. Print out data\n",
    "get_healthcare_info('Get Immediate Help in a Crisis')\n",
    "#use get_healthcare_info() funtion to get contents of specified section title. Print out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National Suicide Prevention Lifeline\n",
      "National Suicide Prevention LifelineCall 1-800-273-TALK (8255); En Español 1-888-628-9454 The Lifeline is a free, confidential crisis hotline that is available to everyone 24 hours a day, seven days a week. The Lifeline connects callers to the nearest crisis center in the Lifeline national network. These centers provide crisis counseling and mental health referrals. People who are deaf, hard of hearing, or have hearing loss can contact the Lifeline via TTY at 1-800-799-4889.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Crisis Text Line\n",
      "Crisis Text LineText “HELLO” to 741741 The Crisis Text hotline is available 24 hours a day, seven days a week throughout the U.S. The Crisis Text Line serves anyone, in any type of crisis, connecting them with a crisis counselor who can provide support and information.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Veterans Crisis Line\n",
      "Veterans Crisis Line Call 1-800-273-TALK (8255) and press 1 or text to 838255 The Veterans Crisis Line is a free, confidential resource that connects veterans 24 hours a day, seven days a week with a trained responder. The service is available to all veterans, even if they are not registered with the VA or enrolled in VA healthcare. People who are deaf, hard of hearing, or have hearing loss can call 1-800-799-4889.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Disaster Distress Helpline\n",
      "Disaster Distress HelplineCall 1-800-985-5990 or text “TalkWithUs” to 66746 The disaster distress helpline provides immediate crisis counseling for people who are experiencing emotional distress related to any natural or human-caused disaster. The helpline is free, multilingual, confidential, and available 24 hours a day, seven days a week.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "Contact social media outlets directly\n",
      "Contact social media outlets directly if you are concerned about a friend’s social media updates or dial 911 in an emergency.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "NIMH 5 action steps for helping someone in emotional pain\n",
      "View the NIMH 5 action steps for helping someone in emotional pain infographic to see how you can help those in distress.\n",
      "Transforming the understanding\n",
      " and treatment of mental illnesses.\n",
      "therapy\n",
      "medication\n",
      "bringing up your mental health concerns and asking for help\n",
      "Substance Abuse and Mental Health Services Administration (SAMHSA)\n",
      "Behavioral Health Treatment Locator\n",
      "Health Resources and Services Administration (HRSA):\n",
      "Centers for Medicare & Medicaid Services (CMS)\n",
      "The National Library of Medicine (NLM) MedlinePlus\n",
      "directories\n",
      "organizations\n",
      "Mental Health and Addiction Insurance Help\n",
      "Anxiety and Depression Association of America\n",
      "Depression and Bipolar Support Alliance\n",
      "Mental Health America\n",
      "National Alliance on Mental Illness\n",
      "Help for Service Members and Their Families page\n",
      "U.S. Department of Veteran Affairs’ mental health page\n",
      "csv complete\n"
     ]
    }
   ],
   "source": [
    "#write .py file to a csv file\n",
    "#assign variable to 'Link' & 'Description' for headers of csv file\n",
    "Headers = ['Link', 'Desription']\n",
    "#assign variables to data from function 'get_link_info('Get Immediate Help in a Crisis')' to be added to csv file\n",
    "dict_data = get_link_info('Get Immediate Help in a Crisis')\n",
    "#assign variables to data from function 'get_link_info('Find a Health Care Provider or Treatment')' to be added to csv file\n",
    "healthcare_data = get_healthcare_info('Find a Health Care Provider or Treatment')\n",
    "#Add data variables together to create one combined variable\n",
    "NIMH_data = dict_data + healthcare_data \n",
    "#Set variable for csv file name\n",
    "csv_file = \"NIMH_data_final.csv\"\n",
    "#name csv file\n",
    "try:\n",
    "#try statement\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "#open csv and write 'w' as csv file\n",
    "#You can also read csv files with 'r'\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=Headers)\n",
    "        #Variable for writer which creates csv rows / name of headers\n",
    "        writer.writeheader()\n",
    "        for data in NIMH_data:\n",
    "            writer.writerow(data)\n",
    "    print('csv complete')\n",
    "#print when csv file is complete\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "    #print if error occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**National Allience for Mental Illness(NAMI) Web Scrape by: Hernan Carvente-Martinez**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are keywords that we searched on the nami website. \n",
    "# For 'African American', the %20 signifies a space in the url line\n",
    "keywords = ['Black','African%20American', 'Latino', 'Latinx','Latina',\n",
    "\t\t\t'Indigenous']\n",
    "\n",
    "# The set() method below creates an empty set where unique search results\n",
    "# are being placed once the line of code is run\n",
    "unique_results = set()\n",
    "\n",
    "# The lines of code below we are accessing a csv file where the unique results\n",
    "# above will be housed once the for loop goes through all the search keywords\n",
    "with open('nami_list.csv', newline='', mode='w') as csvfile:\n",
    "\tfieldnames = ['title', 'summary', 'link']\n",
    "\tnami_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\tnami_writer.writeheader()\n",
    "\n",
    "\t# Each keyword brings up multiple result pages so the for loop below goes \n",
    "\t# through every page of each keyword.\n",
    "\tfor number in range(1,10):\n",
    "\t\t#The for loop below is requesting the nami search page and going \n",
    "\t\t# through each of the keywords listed in the keywords list above. \t\t\n",
    "\t\tfor keyword in keywords:\n",
    "\t\t\t# This line of code contains the url for the nami search page.\n",
    "\t\t\t# We changed the keywork and the page number using the for loops\n",
    "\t\t\t# above to go through all the results.\n",
    "\t\t\turl = f'https://www.nami.org/Search?searchtext={keyword}&searchmode=allwords&bygroup=&bytopic=&bytype=139-141-142-143-144-145-146-147-149-153&page={number}'\n",
    "\t\t\t# The line of code below requests the nami url in text format \n",
    "\t\t\t# so that we can read and view the search contents in terminal \n",
    "\t\t\tnami_info = requests.get(url).text\n",
    "\t\t\t# The line of code below takes the url request above and creates\n",
    "\t\t\t# a soup object to parse the data\n",
    "\t\t\tsoup = BeautifulSoup(nami_info, 'lxml')\n",
    "\t\t\t\n",
    "\t\t\t# This is an empty list to place the title of each resource\n",
    "\t\t\ttitles_list = []\n",
    "\t\t\t# This is an empty list to place the summary of each resource \n",
    "\t\t\tsummary_list = []\n",
    "\t\t\t# This is an empty list to palce the url of each resource\n",
    "\t\t\turl_list = []\n",
    "\t\t\t\n",
    "\t\t\t# The for loop below is finding all of the tags in the html code \n",
    "\t\t\t# with the specific \"class\" for all the titles. \n",
    "\t\t\tfor resource_title in soup.find_all('div', class_='search-resultsTitle'):\n",
    "\t\t\t\t# This line defines titles with the specific anchor element\n",
    "\t\t\t\t# in the div tag where the title exists.\n",
    "\t\t\t\ttitle = resource_title.a.text\n",
    "\t\t\t\t# This line of code takes the title and adds it to the empty \n",
    "\t\t\t\t# titles list above and uses the strip function to remove\n",
    "\t\t\t\t# all of the extra spacing.\n",
    "\t\t\t\ttitles_list.append(title.strip())\n",
    "\n",
    "\t\t\t# The for loop below is finding all of the tags in the html code \n",
    "\t\t\t# with the specific \"class\" for all the summaries.\n",
    "\t\t\tfor resource_summary in soup.find_all('div', class_='search-resultsSummary'):\n",
    "\t\t\t\t# This line defines summary with the specific anchor element\n",
    "\t\t\t\t# in the div tag where the summary exists.\n",
    "\t\t\t\tsummary = resource_summary.text\n",
    "\t\t\t\t# This line of code takes the summary and adds it to the empty \n",
    "\t\t\t\t# summaries list above and uses the strip function to remove\n",
    "\t\t\t\t# all of the extra spacing.\n",
    "\t\t\t\tsummary_list.append(summary.strip())\n",
    "\n",
    "\t\t\t# The for loop below is finding all of the tags in the html code \n",
    "\t\t\t# with the specific \"class\" for all the url's.\n",
    "\t\t\tfor resource_url in soup.find_all('div', class_='search-resultsRelURL'):\n",
    "\t\t\t\t# This line defines summary with the specific anchor element\n",
    "\t\t\t\t# in the div tag where the url exists.\n",
    "\t\t\t\tlink = resource_url.a.get('href')\n",
    "\t\t\t\t# This line of code takes the url and adds it to the empty \n",
    "\t\t\t\t# url's list above and uses the strip function to remove\n",
    "\t\t\t\t# all of the extra spacing.\n",
    "\t\t\t\turl_list.append(link.strip())\n",
    "\n",
    "\t\t\t# The line below loops through each index in the lists that were \n",
    "\t\t\t# created. With each list being the same the same length.\n",
    "\t\t\tfor l in range(len(titles_list)):\n",
    "\t\t\t\t# This line of code adds each individual title with the\n",
    "\t\t\t\t# corresponding summary and url into the unique results empty\n",
    "\t\t\t\t# set created above.\t\t\n",
    "\t\t\t\tunique_results.add((titles_list[l], summary_list[l], url_list[l]))\t\t\n",
    "\n",
    "\t#This for loop goes through each result in the unique results set\n",
    "\tfor result in unique_results:\n",
    "\t\t# The line of code below adds each unique result to the CSV file we \n",
    "\t\t# created to house the results of the webscraping\t\n",
    "\t\tnami_writer.writerow({'title': result[0] , 'summary': result[1], 'link': result[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
